input {
  redis {
    host => "<%= p("redis.host") %>"
    port => <%= p("redis.port") %>

    # these settings should match the output of the agent
    data_type => "list"
    key => "<%= p('logstash.redis.key') %>"
  }
}


filter {
  if [type] in ["syslog", "relp"] {
    # syslog/relp

    grok {
      match => { "message" => "(?:%{INT:syslog6587_msglen} )?<%%{POSINT:syslog_pri}>(?:%{NONNEGINT:syslog5424_ver} )?(?:%{SYSLOGTIMESTAMP:syslog_timestamp}|%{TIMESTAMP_ISO8601:syslog_timestamp}) %{SYSLOGHOST:syslog_hostname} %{DATA:syslog_program}(?:\[%{POSINT:syslog_pid}\])?(:)? %{GREEDYDATA:syslog_message}" }
      add_field => [ "received_at", "%{@timestamp}" ]
      add_field => [ "received_from", "%{host}" ]
      add_tag => [ "syslog_standard" ]
      tag_on_failure => ["_grokparsefailure-syslog_standard"]
    }

    if !("_grokparsefailure-syslog_standard" in [tags]) {
      syslog_pri { }

      date {
        match => [ "syslog_timestamp", "MMM  d HH:mm:ss", "MMM dd HH:mm:ss", "ISO8601" ]
        timezone => "UTC"
      }

      # hostname: handle syslog configurations where hostname is localhost
      if ([syslog_hostname] == "localhost" ) {
        grok {
          match => { "received_from" => "%{IPORHOST:syslog_hostname}(?::%{POSINT:syslog_port})?" }
          overwrite => [ "syslog_hostname", "syslog_port" ]
          tag_on_failure => [ "_grokparsefailure-syslog_standard-hostname"]
        }
      }

      mutate {
        replace => [ "source.host", "%{syslog_hostname}" ]
      }

      mutate {
        convert => [ "syslog5424_ver", "integer" ]
        convert => [ "syslog6587_msglen", "integer" ]
        remove_field => [
          #"syslog_pri",
          "syslog_hostname",
          "syslog_port",
          "syslog_timestamp"
        ]
      }
    }

  }


  if [type] in ["syslog", "relp"] and [source.host] == "loggregator" {
    # Parse Cloud Foundry logs from loggregator (syslog)
    # see https://github.com/cloudfoundry/loggregator/blob/master/src/loggregator/sinks/syslogwriter/syslog_writer.go#L156

    grok {
      match => { "syslog_message" => "\[(?<log_source>[^/\]]+)(?:/(?<log_source_id>[^\]]+))?\] \- \-(?: %{GREEDYDATA:message})?" }
        tag_on_failure => [
        "_grokparsefailure-cf-loggregator"
        ]
      }

      if !("_grokparsefailure-cf-loggregator" in [tags]) {
        if [message] =~ /^\s*{".*}\s*$/ {
          mutate {
            rename => [ "message", "_message_json" ]
          }

          json {
            source => "_message_json"
          }

          # @todo seems like some messages have @timestamp in them? seems ci-specific
          date {
            match => [ "@timestamp", "ISO8601" ]
          }

          mutate {
            remove_field => [ "_message_json" ]
          }
        }

        mutate {
          rename => [ "syslog_program", "source.app_id" ]
        }

        mutate {
          add_tag => "cloudfoundry_loggregator"
          remove_field => "syslog_facility"
          remove_field => "syslog_facility_code"
          remove_field => "syslog_message"
          remove_field => "syslog_severity"
          remove_field => "syslog_severity_code"
          remove_field => "syslog5424_ver"
          remove_field => "syslog6587_msglen"
        }
      }

    } else if [type] in ["syslog", "relp"] and [syslog_program] =~ /vcap\..*/ {
      # Parse Cloud Foundry logs from syslog_aggregator

      grok {
        match => { "syslog_message" => "(?:\[job=%{NOTSPACE:job.name}|-) +(?:index=%{NOTSPACE:job.index}\]|-) %{GREEDYDATA:_message_json}" }
        tag_on_failure => [
        "_grokparsefailure-cf-vcap"
        ]
      }

      if !("_grokparsefailure-cf-vcap" in [tags]) {
        kv {
          source => "msgdata"
          field_split => " "
          target => "msgdata"
        }

        if [_message_json] =~ /^\s*{".*}\s*$/ {
          json {
            source => "_message_json"
            remove_field => "_message_json"
          }
        } else {
          mutate {
            rename => [ "_message_json", "message" ]
          }
        }

        mutate {
          rename => [ "syslog_program", "shipper.name" ]
          replace => [ "job.host", "%{source.host}" ]
          gsub => [
          "shipper.name", "\.", "_",
          "job.name", "\.", "_"
          ]
        }

        if [source] == "NatsStreamForwarder" {
          json {
            source => "[data][nats_message]"
            target => "nats_message"
          }

          mutate {
            remove_field => "[data][nats_message]"
          }
        }

        mutate {
          add_tag => "cloudfoundry_vcap"
          replace => [ "shipper.priority", "%{syslog_pri}" ]
          replace => [ "shipper.name", "%{shipper.name}_%{type}" ]
          replace => [ "type", "%{type}_cf" ]
        }

        mutate {
          remove_field => "syslog_facility"
          remove_field => "syslog_facility_code"
          remove_field => "syslog_message"
          remove_field => "syslog_severity"
          remove_field => "syslog_severity_code"
        }
      }

    }

  }



output {

  elasticsearch {
    host => "<%= p("elasticsearch.host") %>"
    index => "<%= p("logstash.index") %>-%{+YYYY.MM.dd}"
    protocol => "transport"
    idle_flush_time => <%= p("logstash.idle_flush_time") %>
    workers => <%= p("logstash.workers") %>
    cluster => "<%= p("elasticsearch.cluster") %>"
  }
}
